---
title: "Semester Project"
author: "Stephen Trippy"
date: "4/8/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Say hello to Yelp Fusion! This is an API with excellent documentation that essentially allows access to any restaurant in Houston. However, there are limits on the number of restaurants I can pull in any one request, and the search algorithm itself is a bit of a black box. Thus, getting all the data needed to answer meaningful questions becomes a puzzle, one that I'll do my best to solve over the course of this project. In cleaning and manipulating the data, I hope to answer the following questions: 

- Does the average price of restaurants in a given zip code correlate with median income in that zip code? Can we infer why or why not?
- Using review count as a proxy for age, are there certain zip codes that stand out as having older restaurants? Does this correlate with the population of said zip codes?
- Can we accurately map the distribution of the following categories of restaurants?
  - Fast Food
  - Steakhouse
  - Chinese
- Can we accurately map the distribution of expensive restaurants?

Along the way, we'll learn more about the Yelp API, and how to access APIs in general

##Libraries! I need a few:

```{r}
library("dplyr")
library("jsonlite")
library("httr")
library("readxl")
library("tidyr")
library("ggplot2")
library("ggmap")
library("maps")
```

# Part 1: Building the Dataset

## Creating vector of Harris County Zip codes

This will allow us to query restaurants by zip code. Zip code data was copied from
https://www.zillow.com/browse/homes/tx/harris-county/
and pasted into a .csv file

Before doing this, we must make sure that the csv file is in our working directory
```{r}
harris_zips <- read.csv('harris_zipcodes.csv')
```

## Reading in Census Data

Next, we read in census data, which is taken from 2006-2010. While unfortunately the api data is current, we can make a decent assumption that wealth levels per zip code have not changed too much

An added benefit of using census data is that this will give us a list of *only valid* zip codes. *i.e. when we query, we will only be using valid zip codes that won't break the process* 

Census data was sourced from:
https://www.psc.isr.umich.edu/dis/census/Features/tract2zip/

```{r}
#read the demographic data in. cells with no data are marked with a '.'

zip_demographic_data <- read_excel('zipcode_census_data.xlsx', sheet = 'nation', na = ".") %>% 
  rename(zip_code = Zip)
harris_data_by_zip <- inner_join(harris_zips, zip_demographic_data, by = 'zip_code')

#Some of the zip codes in harris_zips had no demographic data, so i decided to inner_join. 
#I could left join though, if I really felt like keeping all of the restaurant data from these zip codes
```

Let's play around with the data we've just gotten
```{r}
harris_data_by_zip %>% 
  arrange(desc(Median)) %>% 
  head(10)

#small sample of the 10 wealthiest zip codes by median income in Harris county. Neat!
```

## Preparing the URI

We now prepare the address we'll be using to query. I have a personal API key, which is stored in a separate file. If you wish to reproduce this code, you'll need to file a Fusion application and provide your own "yelp_api_key.R" file 

The format of this file should be: 

client_ID <- "Your_Application_ID"
yelp_key <- "Your_Yelp_Key"

```{r}
#Loading the API key from a separate file
source("yelp_api_key.R") #allows yelp_key to be available

#info in order to make GET request, using API key as a header
base_uri <- "https://api.yelp.com/v3"
endpoint <- "/businesses/search"
search_uri <- paste0(base_uri, endpoint)

```

## Unleashing the Beast

Now, we prepare to query. My plan is to cycle through every zip code in Harris county, pulling as many restaurants as there are from each zip code. 

There are, however, 2 problems with this approach:

- 1. The yelp api doesn't return data the way I'd like it to. When I tried to query by one particular zip code, restaurants from other zip codes would get pulled back. I attribute this to the fact if you are located in a certain zip code, yelp would want to show you nearby restaurants from different zip codes
  - Solution: I figure that if I pull enough restaurants, the overlap between zip code queries will be enough to make a representative sample. **Note: This is an inherently flawed assumption, but I will be using it regardless to compile my dataset**

- 2. Problems with my nested 'for loop' breaking: Initially, my plan was to cycle through each zip code until I compiled what I thought would be a representative sample of restaurants. However, my loops broke, and I was only able to get a one-time max of 50 results per zip code. 
  - Solution: I'm just going to have to work with the limit I have. Unfortunately, results may be excluded based on whatever parameters the yelp database decides merits a return. Nonetheless, I believe I may still get a representative sample

```{r}
zip_restaurant_list = list()
restaurant_list = list()

for(j in 1:length(harris_data_by_zip$zip_code)){
  zip_code_n <- harris_data_by_zip$zip_code[j]
  
    query_params <- list(
      term = "Restaurants",
      location = zip_code_n,
      sort_by = "distance",
      limit = 50
      #offset = offset_counter
    )
    response <- GET(
      search_uri, 
      query = query_params, 
      add_headers(Authorization = paste("bearer", yelp_key))
    )
    response_text <- content(response, type = "text")
    response_data <- fromJSON(response_text)
    restaurants <- flatten(response_data$businesses)
  
    #each set of restaurants pulled is added to the restaurant list
    restaurant_list[[j]] <- restaurants
}
```

## Compiling our data

We have our restaurant data! However, it's spread out across about 134 lists, with a fair bit of overlapping data. The next step is to combine all these lists into one dataset.

```{r}
#take all of the data we've just extracted. Now bind it into one masterlist
masterlist <-bind_rows(restaurant_list) 

#remove the duplicate restaurants (each restaurant should have a unique id)
masterlist <- masterlist[!duplicated(masterlist$id), ]

#renaming the zip code column will make it so that we can join with the harris_data_by_zip dataset later. We also set this variable's type to double for the same reason
masterlist <- masterlist %>% rename(zip_code = location.zip_code) 
masterlist$zip_code <- as.double(masterlist$zip_code)
```

This ugly bit of code is the final step of data cleaning. We turn the price variable into data we can work with
```{r}

masterlist$price[masterlist$price == "$"] <- 1
masterlist$price[masterlist$price == "$$"] <- 2
masterlist$price[masterlist$price == "$$$"] <- 3
masterlist$price[masterlist$price == "$$$$"] <- 4
masterlist$price <- as.double(masterlist$price)

```

# Part 2: Answering the questions
```{r}
#just some sample code to see where we're at
masterlist %>% 
  arrange() %>% 
  select(zip_code, location.city)

#A join that's very narrow in scope. This allows us to see how many restaurants are present in each zip code, and combines it with the zip code demographic data
joined_masterlist <- masterlist %>% 
  group_by(zip_code) %>% 
  count() %>% 
  right_join(harris_data_by_zip, by = "zip_code")

#Some more sample code: we take the zip code 
joined_masterlist %>% 
  arrange(desc(Median)) %>% 
  head(10)
```

Does the average price of restaurants in a given zip code correlate with median income in that zip code? Can we infer why or why not?
```{r}

zip_data_sublist <- masterlist %>% 
  group_by(zip_code) %>% 
  filter(n() >= 10) %>% #10 was chosen somewhat arbitrarily...
  summarize(restaurant_price = mean(price, na.rm = TRUE)) %>% 
  right_join(harris_data_by_zip, by = "zip_code")

median_price_coeff <- cor(zip_data_sublist$restaurant_price, zip_data_sublist$Median, 
    use = "pairwise.complete.obs") 
#The 'use' command here omits NA results, I believe)

zip_data_sublist %>% 
  ggplot(aes(restaurant_price, y = Median)) + 
  geom_point(alpha = 0.5, color = "purple") + 
  labs(x = "Restaurant Price", y = "Zip Code Median Income",
       subtitle = paste("Correlation coefficient: ", median_price_coeff)) +
  geom_smooth(method = 'lm', lwd = 0.75, se = FALSE, color = "purple")

```

So with a correlation of just under 0.5, we're not looking at a super strong correlation between these two variables. Why might that be?

I have one theory, and it's that the most expensive restaurants are located within the city, (Where many corporate offices are located) whereas most high-earners live in suburbs. Let's use 2 maps to test that.
```{r}

```



The visualizations in this project were made possible by ggmap:
D. Kahle and H. Wickham. ggmap: Spatial Visualization with ggplot2. The R Journal, 5(1), 144-161. URL http://journal.r-project.org/archive/2013-1/kahle-wickham.pdf